# ========== DEFENSE RAG SYSTEM - ENVIRONMENT CONFIGURATION ==========

# ========== REQUIRED ==========
# OpenAI API Key (required for embeddings and generation)
OPENAI_API_KEY=sk-your-api-key-here

# ========== OPTIONAL - HARDWARE OPTIMIZATION ==========
# GPU Usage (auto | true | false)
# - auto: Detect GPU automatically (recommended)
# - true: Force GPU usage (fails if no GPU)
# - false: Force CPU-only
USE_GPU=auto

# Re-ranker (true | false)
# - true: Use BGE-M3 re-ranker (~18s CPU, ~2s GPU)
# - false: Skip re-ranking, rely on RRF fusion (~0s, -3% accuracy)
ENABLE_RERANKER=true

# LLM Judge Validation (true | false)
# - true: Use LLM-as-judge for logical coherence (~5s)
# - false: Skip LLM judge, use only numerical + citation validation (~0s, minimal impact)
ENABLE_LLM_JUDGE=true

# ========== OPTIONAL - MODEL CONFIGURATION ==========
# Embeddings
EMBEDDING_MODEL=text-embedding-3-large

# Generation Models
LLM_MODEL=gpt-4o
LLM_MODEL_MINI=gpt-4o-mini

# ========== OPTIONAL - VECTOR DATABASE ==========
# Type: chromadb (local) | qdrant (server)
VECTOR_DB_TYPE=chromadb

# Qdrant Server (only if VECTOR_DB_TYPE=qdrant)
VECTOR_DB_HOST=vectordb
VECTOR_DB_PORT=6333

# ========== OPTIONAL - PORTS ==========
STREAMLIT_PORT=8501
QDRANT_HTTP_PORT=6333
QDRANT_GRPC_PORT=6334

# ========== NOTES ==========
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# For production deployment, adjust:
# - USE_GPU based on server capabilities
# - ENABLE_RERANKER based on latency requirements
# - ENABLE_LLM_JUDGE based on accuracy vs speed trade-off
